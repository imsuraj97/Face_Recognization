{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.externals import joblib\n",
    "# 1. load the training data (numpy arrays of all the persons)\n",
    "\t\t# x- values are stored in the numpy arrays\n",
    "\t\t# y-values we need to assign for each person\n",
    "# 2. Read a video stream using opencv\n",
    "# 3. extract faces out of it\n",
    "# 4. use knn to find the prediction of face (int)\n",
    "# 5. map the predicted id to name of the user \n",
    "# 6. Display the predictions on the screen - bounding box and name\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "from datetime import date \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input,Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showtable(date):\n",
    "    nos=[]\n",
    "    file_name=date+\".txt\"\n",
    "    with open(file_name,\"a+\") as f:\n",
    "        f.seek(0,0)\n",
    "        nos=f.readlines()\n",
    "    nos=[a[:len(a)-1] for a in nos]\n",
    "\n",
    "    dic={}\n",
    "    data=[]\n",
    "    with open(\"data.txt\",\"a+\") as f:\n",
    "        f.seek(0,0)\n",
    "        data=f.readlines()\n",
    "    data=[a[:len(a)-1] for a in data]\n",
    "    for temp in data:\n",
    "        ls=temp.split(\" \")\n",
    "        dic[ls[0]]=ls[1]+\" \"+ ls[2]\n",
    "    space=13\n",
    "    print(\"Roll NO.\",\" \"*space,\"|\"\"NAME\",\" \"*space,\"|\"\"DEPARTMENT\",\" \"*space,\"|\",\"DATE\")\n",
    "    print()\n",
    "    for temp in nos:\n",
    "        namedept=dic[temp].split(\" \")\n",
    "        print(temp,\" \"*(8-len(temp)+space),\"|\",namedept[0],\" \"*(4-len(namedept[0])+space),\"|\",namedept[1],\" \"*(10-len(namedept[1])+space),\"|\",date[0:4]+\"/\"+date[4:6]+\"/\"+date[6:]);\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    #Init Camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Face Detection\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "    skip = 0\n",
    "    dataset_path = 'data/'\n",
    "\n",
    "\n",
    "\n",
    "    class_id = 0 # Labels for the given file\n",
    "    names = {} #Mapping btw id - name\n",
    "\n",
    "\n",
    "    # Data Preparation for labeling\n",
    "    for fx in os.listdir(dataset_path):\n",
    "        if fx.endswith('.npy'):\n",
    "            #Create a mapping btw class_id and name\n",
    "            #class_id =int(fx[:-4]) \n",
    "            names[class_id] = fx[:-4]\n",
    "            print(\"Loaded \"+fx)\n",
    "            data_item = np.load(dataset_path+fx)\n",
    "\n",
    "            class_id=class_id+1\n",
    "            #Create Labels for the class\n",
    "            target = class_id*np.ones((data_item.shape[0],))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #joblib_file = \"joblib_model.pkl\"\n",
    "\n",
    "\n",
    "    # Load from file\n",
    "    #classifier = joblib.load(joblib_file)\n",
    "    model = load_model(\"model.h5\")\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "    # Testing \n",
    "\n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "        if ret == False:\n",
    "            continue\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "        if(len(faces)==0):\n",
    "            continue\n",
    "\n",
    "        for face in faces:\n",
    "            x,y,w,h = face\n",
    "\n",
    "            #Get the face ROI\n",
    "            offset = 17\n",
    "            face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "            \n",
    "            face_section = cv2.resize(face_section,(28,28))\n",
    "            image = tf.cast(face_section, tf.float32)\n",
    "            #Predicted Label (out)\n",
    "            #out = knn(trainset,face_section.flatten())\n",
    "            img = np.reshape(image,[1,28,28,3])\n",
    "            out = model.predict_classes(img)\n",
    "            #print(out)\n",
    "\n",
    "            #Display on the screen the roll no. and rectangle around it\n",
    "            pred_name = names[out[0]]\n",
    "            \n",
    "            ##from here you have to call sql database function and pass pred_name as argument  ----- \n",
    "            file_name_date=date.today()\n",
    "            file_name=file_name_date.strftime('%Y%m%d')+\".txt\"\n",
    "            flag=1\n",
    "            nos=[]\n",
    "            with open(file_name,\"a+\") as f:\n",
    "                f.seek(0,0)\n",
    "                nos=f.readlines()\n",
    "            nos=[a[:len(a)-1] for a in nos]\n",
    "            \n",
    "            if pred_name not in nos:\n",
    "                with open(file_name,\"a+\") as f:\n",
    "                    f.write(pred_name+'\\n');\n",
    "\n",
    "            cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "        cv2.imshow(\"Faces\",frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key==ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    #Init Camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Face Detection\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "    skip = 0\n",
    "    face_data = []\n",
    "    dataset_path = 'data/'\n",
    "    file_name = input(\"Enter the roll number of the person : \")\n",
    "    person_name=input(\"Enter the name of person :  \")\n",
    "    dep_name=input(\"Enter Department name : \")\n",
    "    final=file_name+\" \"+person_name+\" \"+dep_name+\"\\n\"\n",
    "    with open(\"data.txt\",\"a+\") as f:\n",
    "        f.write(final);\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        if ret==False:\n",
    "            continue\n",
    "\n",
    "        #gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "        if len(faces)==0 :\n",
    "            continue\n",
    "\n",
    "        faces = sorted(faces,key=lambda f:f[2]*f[3])\n",
    "\n",
    "        # Pick the last face (because it is the largest face acc to area(f[2]*f[3]))\n",
    "        for face in faces[-1:]:\n",
    "            x,y,w,h = face\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "            #Extract (Crop out the required face) : Region of Interest\n",
    "            offset = 17\n",
    "            face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "            face_section = cv2.resize(face_section,(28,28))\n",
    "\n",
    "            skip += 1\n",
    "            if skip%10==0:\n",
    "                face_data.append(face_section)\n",
    "                print(len(face_data))\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Frame\",frame)\n",
    "        #cv2.imshow(\"Face Section\",face_section)\n",
    "\n",
    "        key_pressed = cv2.waitKey(1) & 0xFF\n",
    "        if key_pressed == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Convert our face list array into a numpy array\n",
    "    face_data = np.asarray(face_data)\n",
    "    print(face_data.shape)\n",
    "    face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "    print(face_data.shape)\n",
    "\n",
    "    # Save this data into file system\n",
    "    np.save(dataset_path+file_name+'.npy',face_data)\n",
    "\n",
    "\n",
    "    ##Training\n",
    "    face_data = [] \n",
    "    labels = []\n",
    "\n",
    "    class_id = 0 # Labels for the given file\n",
    "    names = {} #Mapping btw id - name\n",
    "\n",
    "    # Data Preparation\n",
    "    for fx in os.listdir(dataset_path):\n",
    "        if fx.endswith('.npy'):\n",
    "            #Create a mapping btw class_id and name\n",
    "            #class_id =int(fx[:-4])\n",
    "            names[class_id] = fx[:-4]\n",
    "            print(\"Loaded \"+fx)\n",
    "            data_item = np.load(dataset_path+fx)\n",
    "            face_data.append(data_item)\n",
    "\n",
    "            #Create Labels for the class\n",
    "            target = class_id*np.ones((data_item.shape[0],))\n",
    "            class_id += 1\n",
    "            labels.append(target)\n",
    "\n",
    "    face_dataset = np.concatenate(face_data,axis=0)\n",
    "    face_labels = np.concatenate(labels,axis=0)\n",
    "\n",
    "    print(face_dataset.shape)\n",
    "    print(face_labels.shape)\n",
    "\n",
    "    #classifier = svm.SVC(gamma=0.001)\n",
    "    #fit to the trainin data\n",
    "    #classifier.fit(face_dataset,face_labels)\n",
    "    #print(classifier.score(face_dataset,face_labels))\n",
    "    \n",
    "    X_train = face_dataset.reshape((-1,28,28,3))\n",
    "    Y_train = np_utils.to_categorical(face_labels)\n",
    "    classes=Y_train.shape[1];\n",
    "    print(classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(28,28,3)))\n",
    "    model.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Convolution2D(32,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(8,(5,5),activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(classes,activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    model.fit(X_train,Y_train,epochs=20,shuffle=True,batch_size=4,validation_split=0.20)\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "    # Save to the model in the current working directory\n",
    "    #joblib_file = \"joblib_model.pkl\"\n",
    "    #joblib.dump(model, joblib_file)\n",
    "    model.save(\"model.h5\")\n",
    "    print(\"Data Successfully saved and Trained\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Press 1 for new entry/to update entry\n",
      "Press 2 to run for attendance\n",
      "Press 3 to see the attendace history\n",
      "press 4 to Quite\n",
      "Enter Your Choice:  2\n",
      "Loaded .npy\n",
      "Loaded 205112002.npy\n",
      "Loaded 205117005.npy\n",
      "Loaded 205117007.npy\n",
      "Loaded 205118007.npy\n",
      "Loaded 205118009.npy\n",
      "Loaded 5421.npy\n",
      "\n",
      "\n",
      "Press 1 for new entry/to update entry\n",
      "Press 2 to run for attendance\n",
      "Press 3 to see the attendace history\n",
      "press 4 to Quite\n",
      "Enter Your Choice:  4\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    while 1:\n",
    "        print()\n",
    "        print()\n",
    "        print(\"Press 1 for new entry/to update entry\")\n",
    "        print(\"Press 2 to run for attendance\")\n",
    "        print(\"Press 3 to see the attendace history\")\n",
    "        print(\"press 4 to Quite\")\n",
    "\n",
    "        \n",
    "        x=int(input(\"Enter Your Choice:  \"))\n",
    "        if x==1:\n",
    "            train()\n",
    "        elif x==2:\n",
    "            test()\n",
    "        elif x==3:\n",
    "            date=input(\"Enter Date in YYYYMMDD Format\")\n",
    "            print(\"\\n\\n\\n\")\n",
    "            showtable(date)\n",
    "            print(\"\\n\\n\\n\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
